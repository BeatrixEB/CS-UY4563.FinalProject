{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np # library which more efficiently allows you to work with large multidimensional arrays and matrices.  It has functions that operate on the arrays/matrices\n",
    "import pandas as pd # built on numpy.  Makes it easier to read in data and clean data among other things\n",
    "\n",
    "# import sklearn\n",
    "\n",
    "# from sklearn import linear_model\n",
    "# from sklearn.linear_model import Lasso\n",
    "# from sklearn.linear_model import Ridge\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder,OneHotEncoder # Scaling is suggested when running a gradient descent algorithm\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.neural_network import MLPClassifier\n",
    "# import numpy.random as r\n",
    "\n",
    "# from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import accuracy_score,r2_score,mean_squared_error,accuracy_score, precision_score, recall_score\n",
    "\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense, Dropout, Flatten\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_path = \"rf_signal_data.csv\"\n",
    "rf_data = pd.read_csv(file_path)\n",
    "\n",
    "rf_data = rf_data.sample(n = 1000, replace = True, random_state = 42)\n",
    "#check how the data looks\n",
    "#print(rf_data)\n",
    "\n",
    "#Let's hot encode the modulation types, weather conditions, interference type, Antenna Type, and device status using integers\n",
    "label_encoder = LabelEncoder()\n",
    "rf_data['Interference Type'] = label_encoder.fit_transform(rf_data['Interference Type']) + 1\n",
    "rf_data['Weather Condition'] = label_encoder.fit_transform(rf_data['Weather Condition']) + 1\n",
    "rf_data['Device Status'] = label_encoder.fit_transform(rf_data['Device Status']) + 1\n",
    "rf_data['Antenna Type'] = label_encoder.fit_transform(rf_data['Antenna Type']) + 1\n",
    "# print(rf_data)\n",
    "\n",
    "X = rf_data.loc[:,~rf_data.columns.isin(['Modulation','Timestamp','Location','Device Type','Latitude','Longitude','Altitude','Air Pressure','I/Q Data','Modulation_Original'])]\n",
    "y = rf_data['Modulation']\n",
    "\n",
    "#Split the data into test data and validation data\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y,random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "#print(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "model = SVC(kernel='sigmoid')\n",
    "model.fit(X_train_pca, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train = model.predict(X_train_pca)\n",
    "y_pred_test = model.predict(X_test_pca)\n",
    "\n",
    "accuracy_train = accuracy_score(y_train,y_pred_train)\n",
    "accuracy_val = accuracy_score(y_test, y_pred_test)\n",
    "print (f\"Training Accuracy:\", accuracy_train, f\" Validation Accuracy: \" ,accuracy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(X)\n",
    "pca = PCA(n_components=2)\n",
    "X2 = X # pca.fit_transform(X)\n",
    "training_split_sizes = [i * (10 ** (-2)) for i in range(10, 100, 10)]\n",
    "# print(training_split_sizes)\n",
    "training_samples = []\n",
    "for train_size in training_split_sizes:\n",
    "    \n",
    "    X_train_pca, X_test_pca, y_train, y_test = train_test_split(X2, y, train_size=train_size, random_state=42)\n",
    "    training_samples.append((pca.fit_transform(X_train_pca), pca.fit_transform(X_test_pca), y_train, y_test))\n",
    "\n",
    "# print(X2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n",
      "0 2\n",
      "0 3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "kern = ['linear','poly','rbf','sigmoid']\n",
    "for i in range(len(kern)):\n",
    "  print(i, '1')\n",
    "  train_error_arr = []\n",
    "  test_error_arr = []\n",
    "  for sample in training_samples:\n",
    "      print(i, '2')\n",
    "      X_train_pca, X_test_pca, y_train, y_test = sample\n",
    "      \n",
    "\n",
    "      model = SVC(kernel = kern[i])\n",
    "      print(i, '3')\n",
    "      model.fit(X_train_pca, y_train)\n",
    "      print(i, '4')\n",
    "\n",
    "      # Make predictions\n",
    "      y_pred_train = model.predict(X_train_pca)\n",
    "      y_pred_test = model.predict(X_test_pca)\n",
    "\n",
    "      # Calculate accuracy\n",
    "      error_train = 1 - accuracy_score(y_train, y_pred_train)\n",
    "      error_test = 1 - accuracy_score(y_test, y_pred_test)\n",
    "    \n",
    "      train_error_arr.append(error_train)\n",
    "      test_error_arr.append(error_test)\n",
    "\n",
    "      #print(f\"Training Accuracy using size = {train_size:.2f}: {accuracy_train:.4f}, Validation Accuracy using size = {train_size:.2f}: {accuracy_test:.4f}\")\n",
    "\n",
    "      # Plotting the results\n",
    "  # print(i, '5')\n",
    "  # plt.plot(training_split_sizes, train_error_arr, label='Training Error')\n",
    "  # plt.plot(training_split_sizes, test_error_arr, label='Validation Error')\n",
    "  # plt.xlabel('Training Size')\n",
    "  # plt.ylabel('Error')\n",
    "  # plt.title(f'Training and Validation Error vs Training Size using a {kern[i]} kernal type')\n",
    "  # plt.legend()\n",
    "  # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = ['linear','poly','rbf','sigmoid']\n",
    "\n",
    "\n",
    "\n",
    "X_train_pca, X_test_pca, y_train, y_test = training_samples[0]\n",
    "print('2')\n",
    "\n",
    "model = SVC(kernel=kernels[1])\n",
    "print('3')\n",
    "model.fit(X_train_pca, y_train)\n",
    "print('3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

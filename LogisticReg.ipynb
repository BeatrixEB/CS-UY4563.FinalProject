{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "# import sklearn\n",
    "# from sklearn import linear_model\n",
    "from sklearn.linear_model import Lasso, Ridge, LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder,OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,r2_score, confusion_matrix\n",
    "import numpy.random as r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"rf_signal_data.csv\"\n",
    "rf_data = pd.read_csv(file_path)\n",
    "\n",
    "#check how the data looks\n",
    "#print(rf_data)\n",
    "dnnd = 7\n",
    "#Let's hot encode the modulation types, weather conditions, interference type, Antenna Type, and device status using integers\n",
    "label_encoder = LabelEncoder()\n",
    "rf_data['Modulation_Original'] = rf_data['Modulation']\n",
    "rf_data['Modulation'] = label_encoder.fit_transform(rf_data['Modulation']) + 1  # Add 1 to avoid 0 indexing\n",
    "rf_data['Interference Type'] = label_encoder.fit_transform(rf_data['Interference Type']) + 1\n",
    "rf_data['Weather Condition'] = label_encoder.fit_transform(rf_data['Weather Condition']) + 1\n",
    "rf_data['Device Status'] = label_encoder.fit_transform(rf_data['Device Status']) + 1\n",
    "rf_data['Antenna Type'] = label_encoder.fit_transform(rf_data['Antenna Type']) + 1\n",
    "rf_data['Device Type'] = label_encoder.fit_transform(rf_data['Device Type']) + 1\n",
    "# print(rf_data)\n",
    "\n",
    "X = rf_data.loc[:,~rf_data.columns.isin(['Device Status','Modulation','Timestamp','Location','Latitude','Longitude','Altitude','Air Pressure','I/Q Data','Modulation_Original','Weather Condition','Antenna Type', 'Battery Level' ])]\n",
    "y = rf_data['Modulation']\n",
    "\n",
    "#Split the data into test data and validation data\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y,random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# print(X)\n",
    "# print(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Analysis I: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainingError, validationError, variance, recall = [[1, 2, 3, 4, 5],[1, 2, 3, 4, 5],[1, 2, 3, 4, 5]], [], [], []\n",
    "# for each in overfitting(3):\n",
    "#     for each in regularization(5):\n",
    "#         train the Model\n",
    "#         trainingError[overfit][regular] = training error of this model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the data so that we can perform logistic regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = np.ones((X_train.shape[0],1))\n",
    "ones2 = np.ones((X_test.shape[0],1))\n",
    "X_train = np.hstack((ones,X_train))\n",
    "X_test = np.hstack((ones2,X_test))\n",
    "y_train = np.array(y_train).reshape(-1, 1)\n",
    "y_test = np.array(y_test).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# class_names=['1', '2', '3', '4', '5', '6'] # name  of classes\n",
    "# fig, ax = plt.subplots()\n",
    "# tick_marks = np.arange(len(class_names))\n",
    "# plt.xticks(tick_marks, class_names)\n",
    "# plt.yticks(tick_marks, class_names)\n",
    "# # create heatmap\n",
    "# sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "# ax.xaxis.set_label_position(\"top\")\n",
    "# plt.tight_layout()\n",
    "# plt.title('Confusion matrix', y=1.1)\n",
    "# plt.ylabel('Actual label')\n",
    "# plt.xlabel('Predicted label')\n",
    "\n",
    "# plt.Text(0.5,257.44,'Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrainPolynomialDegrees = []\n",
    "XTestPolynomialDegrees = []\n",
    "nMin = 1\n",
    "nMax = 3\n",
    "for i in range (nMin, nMax+1):\n",
    "    poly = PolynomialFeatures(i)\n",
    "    XTrainPolynomialDegrees.append(scaler.fit_transform(poly.fit_transform(X_train)))\n",
    "    XTestPolynomialDegrees.append(scaler.fit_transform(poly.fit_transform(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iters = np.array(range(0,num_iters,10))\n",
    "# # iters = np.array(range(num_iters))\n",
    "# plt.plot(iters,log_likelihood_values,'.-',color='green')\n",
    "# plt.xlabel('Number of iterations')\n",
    "# plt.ylabel('Log-Likelihood')\n",
    "# plt.title(\"Log-Likelihood vs Number of Iterations.\")\n",
    "# plt.grid()\n",
    "# plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/validation.py:1229: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/validation.py:1229: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/validation.py:1229: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/validation.py:1229: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/validation.py:1229: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/validation.py:1229: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/validation.py:1229: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/validation.py:1229: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/validation.py:1229: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "CsMin = 1\n",
    "CsMax = 3\n",
    "dict = {}\n",
    "for j in range(CsMin, CsMax+1):\n",
    "    dict[j]={}\n",
    "    for i in range(len(XTrainPolynomialDegrees)):\n",
    "        logreg = LogisticRegressionCV(Cs =j,random_state=32, multi_class='multinomial', penalty = 'l2',max_iter=100)\n",
    "        logreg.fit(XTrainPolynomialDegrees[i], y_train)\n",
    "        y_pred = logreg.predict(XTestPolynomialDegrees[i])\n",
    "        training_error = 1-logreg.score(XTrainPolynomialDegrees[i],y_train)\n",
    "        validation_error = 1-logreg.score(XTestPolynomialDegrees[i],y_test)\n",
    "        cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        dict[j][i] = [training_error, validation_error, cnf_matrix]\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For a degree 1 transformation of the data, with Cs = 0, the training error is 0.17130441845354127 and the validation error is 0.16664230019493176\n",
      "For a degree 1 transformation of the data, with Cs = 1, the training error is 0.18070175438596492 and the validation error is 0.1673489278752437\n",
      "For a degree 1 transformation of the data, with Cs = 2, the training error is 0.19852988953866146 and the validation error is 0.1692738791423002\n",
      "For a degree 2 transformation of the data, with Cs = 0, the training error is 0.17205165692007796 and the validation error is 0.16583820662768034\n",
      "For a degree 2 transformation of the data, with Cs = 1, the training error is 0.18070175438596492 and the validation error is 0.1673489278752437\n",
      "For a degree 2 transformation of the data, with Cs = 2, the training error is 0.1996020142949968 and the validation error is 0.16827485380116958\n",
      "For a degree 3 transformation of the data, with Cs = 0, the training error is 0.17204353476283307 and the validation error is 0.16583820662768034\n",
      "For a degree 3 transformation of the data, with Cs = 1, the training error is 0.18070175438596492 and the validation error is 0.1673489278752437\n",
      "For a degree 3 transformation of the data, with Cs = 2, the training error is 0.19962638076673167 and the validation error is 0.16812865497076024\n"
     ]
    }
   ],
   "source": [
    "for j in range(CsMin, CsMax+1):\n",
    "    for i in range(len(XTrainPolynomialDegrees)):\n",
    "        print(f'For a degree {j} transformation of the data, with Cs = {i}, the training error is {dict[j][i][0]} and the validation error is {dict[j][i][1]}')\n",
    "\n",
    "for j in range(CsMin, CsMax+1):\n",
    "    for i in range(len(XTrainPolynomialDegrees)):\n",
    "        print(f'For a degree {j} transformation of the data, with Cs = {i}, the training accuracy is {1-dict[j][i][0]} and the validation accuracy is {1-dict[j][i][1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnf_matrix = confusion_matrix(y_test, y_pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
